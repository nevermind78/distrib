{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability distributions, random variables\n",
    "\n",
    "---\n",
    "\n",
    "This notebook illustrates the following concepts using simple scripts and functions from `Scipy` and `Numpy` packages.\n",
    "\n",
    "- Random variables\n",
    "- Law of the large number\n",
    "- Expected value\n",
    "- Discrete probability distributions\n",
    "- Concitinuous probability distributions\n",
    "- Moments, variance, and other properties of probability distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Throwing dice many times (illustrating the _Law of large numbers_)\n",
    "When we throw dice a large number of times, the average reaches 3.5 which is the expected value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice = [x for x in range(1,7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"A fair dice has 6 faces:\",dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def throw_dice(n=10):\n",
    "    \"\"\"\n",
    "    Throw a (fair) die n number of times and returns the result in an array\n",
    "    \"\"\"\n",
    "    r = []\n",
    "    for _ in range(n):\n",
    "        r.append(random.choice(dice))\n",
    "    return np.array(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "throw_dice(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "throw_dice(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,5,10,50,100,500,1000,5000,10000]:\n",
    "    print(\"Average of {} dice throws: {}\".format(i,round(throw_dice(i).mean(),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected value of a continuous function\n",
    "\n",
    "__Expected value or mean__: the weighted average of the possible values, using their probabilities as their weights; or the continuous analog thereof.\n",
    "\n",
    "Let $X$ be a random variable with a finite number of finite outcomes $x_1$,$x_2$,$x_3$,... occurring with probabilities $p_1$,$p_2$,$p_3$,... respectively. The expectation of $X$ is, then, defined as\n",
    "\n",
    "$$ E[X]=\\sum_{i=1}^{k}x_{i}\\,p_{i}=x_{1}p_{1}+x_{2}p_{2}+\\cdots +x_{k}p_{k} $$\n",
    "\n",
    "Since, all the probabilities $p_1$, $p_2$, $p_3$, add up to 1, $p_1+p_2+p_3+...=1$, it is the **weighted average**.\n",
    "\n",
    "For, continuous probability distributions, with a density function (PDF) of $f(x)$, the expected value is given by,\n",
    "\n",
    "$$ {\\displaystyle \\operatorname {E} [X]=\\int _{\\mathbb {R} }xf(x)\\,dx.}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's calculate the expected value of the function $P(x)=x.e^{-x}$ between $x=0$ and $x=\\infty$\n",
    "\n",
    "We are trying to compute,\n",
    "$$ \\int _{0}^{\\infty}x.P(x).dx = \\int _{0}^{\\infty}x.[x.e^{-x}].dx = \\int _{0}^{\\infty}x^2.e^{-x}.dx$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    import numpy as np\n",
    "    return x*np.exp(-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,10,0.1)\n",
    "y = func(x)\n",
    "plt.plot(x,y,color='k',lw=3)\n",
    "plt.title(\"Function of $x.e^{-x}$\",fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `scipy.integrate` module\n",
    "We will increase the upper limit of the integral slowly and show that the integral does not change much after a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integral_value=[]\n",
    "for i in range(1,11):\n",
    "    integral=scipy.integrate.quad(func,0,i)[0]\n",
    "    integral_value.append(integral)\n",
    "    print(\"The integral value for upper limit of {} is : {}\".format(i,integral))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,11),integral_value,color='k',lw=3)\n",
    "plt.title(\"Integral of $x.e^{-x}$\",fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation(x):\n",
    "    return x*func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,20,0.1)\n",
    "y = expectation(x)\n",
    "plt.plot(x,y,color='k',lw=3)\n",
    "plt.title(\"Function of $x^2.e^{-x}$\",fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integral_value=[]\n",
    "for i in range(1,11):\n",
    "    integral=scipy.integrate.quad(expectation,0,i)[0]\n",
    "    integral_value.append(integral)\n",
    "    print(\"The integral value for upper limit of {} is : {}\".format(i,integral))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,11),integral_value,color='k',lw=3)\n",
    "plt.title(\"Integral of $x^2.e^{-x}$\",fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete and Continuous Distributions\n",
    "\n",
    "Probability distributions are generally divided into two classes. A __discrete probability distribution__ (applicable to the scenarios where the set of possible outcomes is discrete, such as a coin toss or a roll of dice) can be encoded by a discrete list of the probabilities of the outcomes, known as a [probability mass function](https://en.wikipedia.org/wiki/Probability_mass_function). \n",
    "\n",
    "On the other hand, a __continuous probability distribution__ (applicable to the scenarios where the set of possible outcomes can take on values in a continuous range (e.g. real numbers), such as the temperature on a given day) is typically described by probability density functions (with the probability of any individual outcome actually being 0). Such distributions are generally described with the help of [probability density functions](https://en.wikipedia.org/wiki/Probability_density_function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Essential Terminologies\n",
    "\n",
    "* __Mode__: for a discrete random variable, the value with highest probability (the location at which the probability mass function has its peak); for a continuous random variable, a location at which the probability density function has a local peak.\n",
    "* __Support__: the smallest closed set whose complement has probability zero.\n",
    "* __Head__: the range of values where the pmf or pdf is relatively high.\n",
    "* __Tail__: the complement of the head within the support; the large set of values where the pmf or pdf is relatively low.\n",
    "* __Expected value or mean__: the weighted average of the possible values, using their probabilities as their weights; or the continuous analog thereof.\n",
    "* __Median__: the value such that the set of values less than the median, and the set greater than the median, each have probabilities no greater than one-half.\n",
    "* __Variance__: the second moment of the pmf or pdf about the mean; an important measure of the dispersion of the distribution.\n",
    "* __Standard deviation__: the square root of the variance, and hence another measure of dispersion.\n",
    "\n",
    "* __Symmetry__: a property of some distributions in which the portion of the distribution to the left of a specific value is a mirror image of the portion to its right.\n",
    "* __Skewness__: a measure of the extent to which a pmf or pdf \"leans\" to one side of its mean. The third standardized moment of the distribution.\n",
    "* __Kurtosis__: a measure of the \"fatness\" of the tails of a pmf or pdf. The fourth standardized moment of the distribution.\n",
    "\n",
    "![kurtosis](https://anotherbloodybullshitblog.files.wordpress.com/2016/01/normal-not-always-the-norm.gif?w=809)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick mathematical definitions of mean, variance, skewness, and kurtosis with respect to a PDF $P(x)$\n",
    "\n",
    "$$\\text{1st raw moment } \\mathbf{Mean\\ (1st\\ moment):} \\int x.P(x).dx$$\n",
    "\n",
    "$$\\text{Centralized 2nd moment } \\mathbf{Variance\\ (2nd\\ moment):} \\int (x-\\mu)^2.P(x).dx$$\n",
    "\n",
    "$$\\text{Pearson's 3rd moment (Standardized) }\\mathbf{Skew\\ (3rd\\ moment):} \\int\\left ( \\frac{x-\\mu}{\\sigma} \\right )^3.P(x).dx$$\n",
    "\n",
    "$$\\text{Pearson's 4th moment (Standardized)  }\\mathbf{Kurtosis\\ (4th\\ moment):} \\int\\left ( \\frac{x-\\mu}{\\sigma} \\right )^4.P(x).dx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulii distribution\n",
    "\n",
    "The Bernoulli distribution, named after Swiss mathematician [Jacob Bernoulli](https://en.wikipedia.org/wiki/Jacob_Bernoulli), is the probability distribution of a random variable which takes the value 1 with probability $p$ and the value 0 with probability $q = 1 − p$ — i.e., the probability distribution of any single experiment that asks a ___yes–no question___; the question results in a boolean-valued outcome, a single bit of information whose value is success/yes/true/one with probability $p$ and failure/no/false/zero with probability $q$. \n",
    "\n",
    "It can be used to represent a coin toss where 1 and 0 would represent \"head\" and \"tail\" (or vice versa), respectively. In particular, unfair coins would have $p ≠ 0.5$.\n",
    "\n",
    "![coin](https://raw.githubusercontent.com/tirthajyoti/Stats-Maths-with-Python/master/images/coin_toss.PNG)\n",
    "\n",
    "The probability mass function $f$ of this distribution, over possible outcomes $k$, is\n",
    "\n",
    "$${\\displaystyle f(k;p)={\\begin{cases}p&{\\text{if }}k=1,\\\\[6pt]1-p&{\\text{if }}k=0.\\end{cases}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import bernoulli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random variates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p=0.5 i.e. fair coin\n",
    "bernoulli.rvs(p=0.5,size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loaded coin towards tail, p=0.2 for head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p=0.2 i.e. more tails (0) than heads(1)\n",
    "bernoulli.rvs(p=0.2,size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loaded coin towards head, p=0.8 for head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p=0.8 i.e. more heads (1) than tails (0)\n",
    "bernoulli.rvs(p=0.8,size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note, a single run or even a small number of runs may not produce the expected distribution of 1's and 0's. \n",
    "For example, if you assign $p=0.5$, you may not get half 1's and half 0's every time you evaluate the function. Experiment with $N$ number of trials to see how the probability distribution gradually centers around 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_trials = [10,20,50,100,200,500,1000,2000,5000] # Number of trials\n",
    "pr=0.5 # Fair coin toss probability\n",
    "av = [] # Empty list to store the average of the random variates\n",
    "\n",
    "# Generate 10 variates every time and take the average. That should be # of 1's i.e. 0.5 for a fair coin.\n",
    "for i in N_trials:\n",
    "    for n in range(1,i+1):\n",
    "        av.append(np.mean(bernoulli.rvs(p=pr,size=10)))\n",
    "    if (i==10):\n",
    "        plt.title(\"Distribution with {} trials of 10 coin tosses\".format(i))\n",
    "        plt.hist(av,bins=10,edgecolor='k',color='orange')\n",
    "        plt.xlim(0.0,1.0)\n",
    "        plt.xticks([0.1*i for i in range(11)])\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.title(\"Distribution with {} trials of 10 coin tosses\".format(i))\n",
    "        plt.hist(av,bins=25,edgecolor='k',color='orange')\n",
    "        plt.xlim(0.0,1.0)\n",
    "        plt.xticks([0.1*i for i in range(11)])\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean, variance, skew, and kurtosis\n",
    "Use `bernoulli.stats()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"A fair coin is spinning...\\n\"+\"-\"*30)\n",
    "pr=0.5 # Fair coin toss probability\n",
    "mean, var, skew, kurt = bernoulli.stats(p=pr, moments='mvsk')\n",
    "print(\"Mean:\",mean)\n",
    "print(\"Variance:\",var)\n",
    "print(\"Skew:\",skew)\n",
    "print(\"Kurtosis:\",kurt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNow a biased coin is spinning...\\n\"+\"-\"*35)\n",
    "pr=0.7 # Biased coin toss probability\n",
    "mean, var, skew, kurt = bernoulli.stats(p=pr, moments='mvsk')\n",
    "print(\"Mean:\",mean)\n",
    "print(\"Variance:\",var)\n",
    "print(\"Skew:\",skew)\n",
    "print(\"Kurtosis:\",kurt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability mass function (PMF) and cumulative distribution function (CDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv = bernoulli(0.6)\n",
    "x=0\n",
    "print(\"Probability mass function for {}: {}\".format(x,rv.pmf(x)))\n",
    "x=0.5\n",
    "print(\"Probability mass function for {}: {}\".format(x,rv.pmf(x)))\n",
    "x=1.0\n",
    "print(\"Probability mass function for {}: {}\".format(x,rv.pmf(x)))\n",
    "x=1.2\n",
    "print(\"Probability mass function for {}: {}\".format(x,rv.pmf(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CDF for x < 0:\",rv.cdf(-2))\n",
    "print(\"CDF for 0< x <1:\",rv.cdf(0.75))\n",
    "print(\"CDF for x >1:\",rv.cdf(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binomial distribution\n",
    "\n",
    "The binomial distribution with parameters $n$ and $p$ is the discrete probability distribution of the **number of successes in a sequence of $n$ independent experiments, each asking a _yes–no question_,** and each with its own boolean-valued outcome: a random variable containing single bit of information: success/yes/true/one (with probability $p$) or failure/no/false/zero (with probability $q = 1 − p$). A single success/failure experiment is also called a _Bernoulli trial_ or _Bernoulli experiment_ and a sequence of outcomes is called a _Bernoulli process_. \n",
    "\n",
    "For a single trial, i.e., n = 1, the binomial distribution is a **Bernoulli distribution**. The binomial distribution is the basis for the popular [binomial test](https://en.wikipedia.org/wiki/Binomial_test) of [statistical significance](https://en.wikipedia.org/wiki/Statistical_significance).\n",
    "\n",
    "The binomial distribution is frequently used to model the number of successes in a sample of size n drawn with replacement from a population of size N. If the sampling is carried out without replacement, the draws are not independent and so the resulting distribution is a __[hypergeometric distribution](https://en.wikipedia.org/wiki/Hypergeometric_distribution)__, not a binomial one. However, for N much larger than n, the binomial distribution remains a good approximation, and is widely used.\n",
    "\n",
    "In general, if the random variable $X$ follows the binomial distribution with parameters n ∈ ℕ and p ∈ [0,1], we write X ~ B(n, p). The probability of getting exactly $k$ successes in $n$ trials is given by the probability mass function:\n",
    "\n",
    "$${\\Pr(k;n,p)=\\Pr(X=k)={n \\choose k}p^{k}(1-p)^{n-k}}$$\n",
    "\n",
    "for k = 0, 1, 2, ..., n, where\n",
    "\n",
    "$${\\displaystyle {\\binom {n}{k}}={\\frac {n!}{k!(n-k)!}}}$$\n",
    "\n",
    "![head_tail](https://wp-media.patheos.com/blogs/sites/308/2018/03/Probability-Tree-Diagram-coin-toss-1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random variates\n",
    "8 coins are flipped (or 1 coin is flipped 8 times), each with probability of success (1) of 0.25. This trial/experiment is repeated for 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=binom.rvs(8,0.25,size=10)\n",
    "print(\"Number of success for each trial:\",k)\n",
    "print(\"Average of the success:\", np.mean(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean, variance, skew, and kurtosis\n",
    "\n",
    "$$\\textbf{Mean} = n.p,\\ \\textbf{Variance}= n.p(1 - p), \\textbf{skewness}= \\frac{1-2p}{\\sqrt{n.p(1-p)}}, \\ \\textbf{kurtosis}= \\frac{1-6p(1-p)}{n.p(1-p)}$$\n",
    "\n",
    "Use `binom.stats()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"A fair coin (p=0.5) is spinning 5 times\\n\"+\"-\"*35)\n",
    "pr=0.5 # Fair coin toss probability\n",
    "n=5\n",
    "mean, var, skew, kurt = binom.stats(n=n,p=pr, moments='mvsk')\n",
    "print(\"Mean:\",mean)\n",
    "print(\"Variance:\",var)\n",
    "print(\"Skew:\",skew)\n",
    "print(\"Kurtosis:\",kurt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNow a biased coin (p=0.7) is spinning 5 times...\\n\"+\"-\"*45)\n",
    "pr=0.7 # Biased coin toss probability\n",
    "n=5\n",
    "mean, var, skew, kurt = binom.stats(n=n,p=pr, moments='mvsk')\n",
    "print(\"Mean:\",mean)\n",
    "print(\"Variance:\",var)\n",
    "print(\"Skew:\",skew)\n",
    "print(\"Kurtosis:\",kurt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing probability mass function (PMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=40\n",
    "pr=0.5\n",
    "rv = binom(n,pr)\n",
    "x=np.arange(0,41,1)\n",
    "pmf1 = rv.pmf(x)\n",
    "\n",
    "n=40\n",
    "pr=0.15\n",
    "rv = binom(n,pr)\n",
    "x=np.arange(0,41,1)\n",
    "pmf2 = rv.pmf(x)\n",
    "\n",
    "n=50\n",
    "pr=0.6\n",
    "rv = binom(n,pr)\n",
    "x=np.arange(0,41,1)\n",
    "pmf3 = rv.pmf(x)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title(\"Probability mass function: $\\\\binom{n}{k}\\, p^k (1-p)^{n-k}$\\n\",fontsize=20)\n",
    "plt.scatter(x,pmf1)\n",
    "plt.scatter(x,pmf2)\n",
    "plt.scatter(x,pmf3,c='k')\n",
    "plt.legend([\"$n=40, p=0.5$\",\"$n=40, p=0.3$\",\"$n=50, p=0.6$\"],fontsize=15)\n",
    "plt.xlabel(\"Number of successful trials ($k$)\",fontsize=15)\n",
    "plt.ylabel(\"Probability of success\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the cumulative distrubition function (cdf)\n",
    "\n",
    "Cumulative distribution function for binomial distribution can also be represented in terms of the [regularized incomplete beta function](https://en.wikipedia.org/wiki/Regularized_incomplete_beta_function), as follows\n",
    "\n",
    "$${\\displaystyle {\\begin{aligned}F(k;n,p)&=\\Pr(X\\leq k)\\\\&=I_{1-p}(n-k,k+1)\\\\&=(n-k){n \\choose k}\\int _{0}^{1-p}t^{n-k-1}(1-t)^{k}\\,dt.\\end{aligned}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=40\n",
    "pr=0.5\n",
    "rv = binom(n,pr)\n",
    "x=np.arange(0,41,1)\n",
    "cdf1 = rv.cdf(x)\n",
    "\n",
    "n=40\n",
    "pr=0.3\n",
    "rv = binom(n,pr)\n",
    "x=np.arange(0,41,1)\n",
    "cdf2 = rv.cdf(x)\n",
    "\n",
    "n=50\n",
    "pr=0.6\n",
    "rv = binom(n,pr)\n",
    "x=np.arange(0,41,1)\n",
    "cdf3 = rv.cdf(x)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title(\"Cumulative distribution function: $I_{1-p}(n - k, 1 + k)$\\n\",fontsize=20)\n",
    "plt.scatter(x,cdf1)\n",
    "plt.scatter(x,cdf2)\n",
    "plt.scatter(x,cdf3,c='k')\n",
    "plt.legend([\"$n=40, p=0.5$\",\"$n=40, p=0.3$\",\"$n=50, p=0.6$\"],fontsize=15)\n",
    "plt.xlabel(\"Number of successful trials\",fontsize=15)\n",
    "plt.ylabel(\"Cumulative probability of success\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interval that contains a specific percentage of distribution\n",
    "Use `binom.interval` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=40\n",
    "pr=0.3\n",
    "percent=25\n",
    "interval = binom.interval(percent/100,n,pr,loc=0)\n",
    "print(\"Interval that contains {} percent of distribution with an experiment with {} trials and {} success probability  is: {}\"\n",
    "      .format(percent,n,pr,interval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson Distribution\n",
    "\n",
    "The Poisson distribution (named after French mathematician Siméon Denis Poisson), is a discrete probability distribution that **expresses the probability of a given number of events occurring in a fixed interval of time or space if these events occur with a known constant rate and independently of the time since the last event.** The Poisson distribution can also be used for the number of events in other specified intervals such as distance, area or volume.\n",
    "\n",
    "For instance, an individual keeping track of the amount of mail they receive each day may notice that they receive an average number of 4 letters per day. If receiving any particular piece of mail does not affect the arrival times of future pieces of mail, i.e., if pieces of mail from a wide range of sources arrive independently of one another, then a reasonable assumption is that the number of pieces of mail received in a day obeys a Poisson distribution. Other examples, that may follow a Poisson distribution, include\n",
    "\n",
    "* number of phone calls received by a call center per hour \n",
    "* number of decay events per second from a radioactive source\n",
    "* The number of meteors greater than 1 meter diameter that strike Earth in a year\n",
    "* The number of patients arriving in an emergency room between 10 and 11 pm\n",
    "\n",
    "**Poisson distribution is a limiting case of a Binomial Distribution where the number of trials is sufficiently bigger than the number of successes one is asking about i.e. $n>>1>>p$**\n",
    "\n",
    "An event can occur 0, 1, 2, … times in an interval. The average number of events in an interval is designated $\\lambda$. This is the event rate, also called the rate parameter. The probability of observing k events in an interval is given by the equation\n",
    "\n",
    "${P(k{\\text{ events in interval}})=e^{-\\lambda }{\\frac {\\lambda ^{k}}{k!}}}$\n",
    "\n",
    "where,\n",
    "\n",
    "${\\lambda}$ is the average number of events per interval\n",
    "\n",
    "e is the number 2.71828... (Euler's number) the base of the natural logarithms\n",
    "\n",
    "k takes values 0, 1, 2, …\n",
    "k! = k × (k − 1) × (k − 2) × … × 2 × 1 is the factorial of k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la=0.5\n",
    "rv = poisson(la)\n",
    "x=np.arange(0,11,1)\n",
    "pmf1 = rv.pmf(x)\n",
    "\n",
    "la=1\n",
    "rv = poisson(la)\n",
    "x=np.arange(0,11,1)\n",
    "pmf2 = rv.pmf(x)\n",
    "\n",
    "la=5\n",
    "rv = poisson(la)\n",
    "x=np.arange(0,11,1)\n",
    "pmf3 = rv.pmf(x)\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.title(\"Probability mass function: $e^{-\\lambda}{(\\lambda^k/k!)}$\\n\",fontsize=20)\n",
    "plt.scatter(x,pmf1,s=100)\n",
    "plt.scatter(x,pmf2,s=100)\n",
    "plt.scatter(x,pmf3,c='k',s=100)\n",
    "plt.legend([\"$\\lambda=0.5$\",\"$\\lambda=1$\",\"$\\lambda=5$\"],fontsize=15)\n",
    "plt.xlabel(\"Number of occurences ($k$)\",fontsize=15)\n",
    "plt.ylabel(\"$Pr(X=k)$\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the cumulative distribution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la=0.5\n",
    "rv = poisson(la)\n",
    "x=np.arange(0,11,1)\n",
    "cdf1 = rv.cdf(x)\n",
    "\n",
    "la=2\n",
    "rv = poisson(la)\n",
    "x=np.arange(0,11,1)\n",
    "cdf2 = rv.cdf(x)\n",
    "\n",
    "la=5\n",
    "rv = poisson(la)\n",
    "x=np.arange(0,11,1)\n",
    "cdf3 = rv.cdf(x)\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.title(\"Cumulative distribution function\\n\",fontsize=20)\n",
    "plt.scatter(x,cdf1,s=100)\n",
    "plt.scatter(x,cdf2,s=100)\n",
    "plt.scatter(x,cdf3,c='k',s=100)\n",
    "plt.legend([\"$\\lambda=0.5$\",\"$\\lambda=2$\",\"$\\lambda=5$\"],fontsize=15)\n",
    "plt.xlabel(\"Number of occurences ($k$)\",fontsize=15)\n",
    "plt.ylabel(\"Cumulative distribution function\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moments - mean, variance, skew, and kurtosis\n",
    "Various moments of a Poisson distributed random variable $X$ are as follows:\n",
    "\n",
    "$$ \\textbf{Mean}=\\lambda,\\ \\textbf{Variance}=\\lambda,\\ \\textbf{skewness}=\\frac {1}{\\sqrt{\\lambda}},\\ \\textbf{kurtosis}=\\frac{1}{\\lambda}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometric distribution\n",
    "\n",
    "The geometric distribution is either of two discrete probability distributions:\n",
    "- The probability distribution of the number X of Bernoulli trials needed to get one success, supported on the set { 1, 2, 3, ...}\n",
    "- The probability distribution of the number Y = X − 1 of failures before the first success, supported on the set { 0, 1, 2, 3, ... }\n",
    "\n",
    "Which of these one calls \"the\" geometric distribution is a matter of convention and convenience.\n",
    "\n",
    "These two different geometric distributions should not be confused with each other. Often, the name shifted geometric distribution is adopted for the former one (distribution of the number $X$); however, to avoid ambiguity, it is considered wise to indicate which is intended, by mentioning the support explicitly.\n",
    "\n",
    "The geometric distribution gives the probability that the first occurrence of success requires $k$ independent trials, each with success probability $p$. If the probability of success on each trial is $p$, then the probability that the $k^{th}$ trial (out of $k$ trials) is the first success is\n",
    "\n",
    "${\\Pr(X=k)=(1-p)^{k-1}\\,p\\,}$\n",
    "\n",
    "for $k = 1, 2, 3, ....$\n",
    "\n",
    "The above form of the geometric distribution is used for modeling the number of trials up to and including the first success. By contrast, the following form of the geometric distribution is used for modeling the number of failures until the first success:\n",
    "\n",
    "${\\Pr(Y=k)=(1-p)^{k}\\,p\\,}$\n",
    "\n",
    "for $k = 0, 1, 2, 3, ....$\n",
    "\n",
    "In either case, the sequence of probabilities is a geometric sequence.\n",
    "\n",
    "The geometric distribution is an appropriate model if the following assumptions are true.\n",
    "- The phenomenon being modelled is a sequence of independent trials.\n",
    "- There are only two possible outcomes for each trial, often designated success or failure.\n",
    "- The probability of success, p, is the same for every trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import geom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random variates\n",
    "It is difficult to get a success with low probability, so it takes more trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=geom.rvs(p=0.1,size=10)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easier to get the first success with higher probability, so it takes less number of trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=geom.rvs(p=0.5,size=10)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing probability mass function (PMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0.1\n",
    "rv = geom(p)\n",
    "x=np.arange(1,11,1)\n",
    "pmf1 = rv.pmf(x)\n",
    "\n",
    "p=0.25\n",
    "rv = geom(p)\n",
    "x=np.arange(1,11,1)\n",
    "pmf2 = rv.pmf(x)\n",
    "\n",
    "p=0.75\n",
    "rv = geom(p)\n",
    "x=np.arange(1,11,1)\n",
    "pmf3 = rv.pmf(x)\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.title(\"Probability mass function: $(1-p)^{k-1}p$\\n\",fontsize=20)\n",
    "plt.scatter(x,pmf1,s=100)\n",
    "plt.scatter(x,pmf2,s=100)\n",
    "plt.scatter(x,pmf3,c='k',s=100)\n",
    "plt.plot(x,pmf1)\n",
    "plt.plot(x,pmf2)\n",
    "plt.plot(x,pmf3,c='k')\n",
    "plt.legend([\"$p=0.1$\",\"$p=0.25$\",\"$p=0.75$\"],fontsize=15)\n",
    "plt.xlabel(\"Number of trials till first success ($k$)\",fontsize=15)\n",
    "plt.ylabel(\"$Pr(X=x)$\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing cumulative distribution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0.1\n",
    "rv = geom(p)\n",
    "x=np.arange(1,11,1)\n",
    "cdf1 = rv.cdf(x)\n",
    "\n",
    "p=0.25\n",
    "rv = geom(p)\n",
    "x=np.arange(1,11,1)\n",
    "cdf2 = rv.cdf(x)\n",
    "\n",
    "p=0.75\n",
    "rv = geom(p)\n",
    "x=np.arange(1,11,1)\n",
    "cdf3 = rv.cdf(x)\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.title(\"Cumulative distribution function: $1-(1-p)^k$\\n\",fontsize=20)\n",
    "plt.scatter(x,cdf1,s=100)\n",
    "plt.scatter(x,cdf2,s=100)\n",
    "plt.scatter(x,cdf3,c='k',s=100)\n",
    "plt.plot(x,cdf1)\n",
    "plt.plot(x,cdf2)\n",
    "plt.plot(x,cdf3,c='k')\n",
    "plt.legend([\"$p=0.1$\",\"$p=0.25$\",\"$p=0.75$\"],fontsize=15)\n",
    "plt.xlabel(\"Number of trials till first success ($k$)\",fontsize=15)\n",
    "plt.ylabel(\"$Pr(X\\leq x)$\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected value (mean), variance, skewness, kurtosis\n",
    "Various moments of a geometrically distributed random variable $X$ are as follows:\n",
    "\n",
    "$$ \\textbf{Mean}=\\frac {1}{p},\\ \\textbf{Variance}=\\frac {1-p}{p^2},\\ \\textbf{skewness}=\\frac {2-p}{\\sqrt{1-p}},\\ \\textbf{kurtosis}=6+\\frac{p^2}{1-p}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniform (continuous) distribution\n",
    "\n",
    "This is the distribution of the likelihood of uniformly randomly selecting an item out of a finite collection.\n",
    "\n",
    "We are mostly familiar with the discontinuous version of this distribution. For example, in case of throwing a fair dice, the probability distribution of a single throw is given by: \n",
    "\n",
    "$$ \\left \\{ \\frac{1}{6},\\ \\frac{1}{6}, \\ \\frac{1}{6},\\ \\frac{1}{6},\\ \\frac{1}{6},\\ \\frac{1}{6} \\right \\} $$\n",
    "\n",
    "![dice](https://raw.githubusercontent.com/tirthajyoti/Stats-Maths-with-Python/master/images/dice.PNG)\n",
    "\n",
    "For the continuous case, the PDF looks deceptively simple, but the concept is subtle,\n",
    "\n",
    "$$ f(x)={\\begin{cases}{\\frac {1}{b-a}}&\\mathrm {for} \\ a\\leq x\\leq b,\\\\[8pt]0&\\mathrm {for} \\ x<a\\ \\mathrm {or} \\ x>b\\end{cases}} $$\n",
    "\n",
    "![uniform](https://raw.githubusercontent.com/tirthajyoti/Stats-Maths-with-Python/master/images/uniform_dist.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random variates (default between 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform.rvs(size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the `loc` and `scale` parameters to move the range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random floats between -10 and 0\n",
    "uniform.rvs(loc=-10,scale=10,size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random floats between -10 and +10\n",
    "uniform.rvs(loc=-10,scale=20,size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal (Gaussian) distribution\n",
    "\n",
    "In probability theory, the normal (or Gaussian or Gauss or Laplace–Gauss) distribution is a very common continuous probability distribution. Normal distributions are important in statistics and are often used in the natural and social sciences to represent real-valued random variables whose distributions are not known. A random variable with a Gaussian distribution is said to be normally distributed and is called a normal deviate.\n",
    "\n",
    "The normal distribution is useful because of the **[central limit theorem](https://en.wikipedia.org/wiki/Central_limit_theorem)**. In its most general form, under some conditions (which include finite variance), it states that **averages of samples of observations of random variables independently drawn from independent distributions converge in distribution to the normal**, that is, they become normally distributed when the number of observations is sufficiently large. \n",
    "\n",
    "Physical quantities that are expected to be the sum of many independent processes (such as measurement errors) often have distributions that are nearly normal. Moreover, many results and methods (such as propagation of uncertainty and least squares parameter fitting) can be derived analytically in explicit form when the relevant variables are normally distributed.\n",
    "\n",
    "### PDF and CDF\n",
    "\n",
    "The probability density function (PDF) is given by,\n",
    "$$ f(x\\mid \\mu ,\\sigma ^{2})={\\frac {1}{\\sqrt {2\\pi \\sigma ^{2}}}}e^{-{\\frac {(x-\\mu )^{2}}{2\\sigma ^{2}}}} $$\n",
    "where,\n",
    "- $\\mu$ is the mean or expectation of the distribution (and also its median and mode),\n",
    "- $\\sigma$ is the standard deviation, and $\\sigma^2$ is the variance.\n",
    "\n",
    "Cumulative distribution function (CDF) is given by,\n",
    "$$\\frac{1}{2}\\left [ 1+\\text{erf} \\left ( \\frac{x-\\mu}{\\sigma\\sqrt{2}}\\right ) \\right ]$$\n",
    "\n",
    "![normal](https://raw.githubusercontent.com/tirthajyoti/Stats-Maths-with-Python/master/images/normal.PNG)\n",
    "\n",
    "Scipy Stats page: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html#scipy.stats.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-3, 3, num = 100)\n",
    "constant = 1.0 / np.sqrt(2*np.pi)\n",
    "pdf_normal_distribution = constant * np.exp((-x**2) / 2.0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5));\n",
    "ax.plot(x, pdf_normal_distribution);\n",
    "ax.set_ylim(0);\n",
    "ax.set_title('Normal Distribution', size = 20);\n",
    "ax.set_ylabel('Probability Density', size = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive the familiar 68-95-99.7 rule from the basic definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalProbabilityDensity(x):\n",
    "    constant = 1.0 / np.sqrt(2*np.pi)\n",
    "    return(constant * np.exp((-x**2) / 2.0) )# Integrate PDF from -1 to 1\n",
    "\n",
    "def integrate_normal(num_sigma):\n",
    "    result, _ = scipy.integrate.quad(normalProbabilityDensity, -num_sigma, num_sigma, limit = 1000)\n",
    "    return round(result,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The percentage of data present within 1 standard deviation:\",integrate_normal(1))\n",
    "print(\"The percentage of data present within 2 standard deviations:\",integrate_normal(2))\n",
    "print(\"The percentage of data present within 3 standard deviations:\",integrate_normal(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random variable generation using `Numpy.random` module\n",
    "Numpy offers an amazing module called `Numpy.random`, which has all the important probability distributions built-in for generation. We will check it out for,\n",
    "\n",
    "- Normal\n",
    "- Uniform\n",
    "- Binomial\n",
    "- Chi-square\n",
    "- Poisson\n",
    "- F-distribution and Student's t-distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate normally distributed numbers with various mean and std.dev\n",
    "In `numpy.random.normal` method, the `loc` argument is the mean, adnd the `scale` argument is the std.dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.random.normal(loc=0,scale=np.sqrt(0.2),size=100000)\n",
    "a2 = np.random.normal(loc=0,scale=1.0,size=100000)\n",
    "a3 = np.random.normal(loc=0,scale=np.sqrt(5),size=100000)\n",
    "a4 = np.random.normal(loc=-2,scale=np.sqrt(0.5),size=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(a1,density=True,bins=100,color='blue',alpha=0.5)\n",
    "plt.hist(a2,density=True,bins=100,color='red',alpha=0.5)\n",
    "plt.hist(a3,density=True,bins=100,color='orange',alpha=0.5)\n",
    "plt.hist(a4,density=True,bins=100,color='green',alpha=0.5)\n",
    "plt.xlim(-7,7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dice throws and average them to show the emergence of Normality as per the Central Limit Theorem\n",
    "We can use either `np.random.uniform` or `np.random.randint` to generate dice throws uniformly randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.uniform(low=1.0,high=7.0,size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_throws(num_sample):\n",
    "    int_throws = np.vectorize(int)\n",
    "    throws = int_throws(np.random.uniform(low=1.0,high=7.0,size=num_sample))\n",
    "    return throws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_throws(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(1,7,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_throws(num_throws=5,num_experiment=100):\n",
    "    averages = []\n",
    "    for i in range(num_experiment):\n",
    "        a = dice_throws(num_throws)\n",
    "        av = a.mean()\n",
    "        averages.append(av)\n",
    "    return np.array(averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [50,100,500,1000,5000,10000,50000,100000]:\n",
    "    plt.hist(average_throws(num_throws=20,num_experiment=i),bins=25,edgecolor='k',color='orange')\n",
    "    plt.title(f\"Averaging with 20 throws and repeating it for {i} times\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-square ($\\chi^2$) distribution as a sum of squared Normally distributed variables\n",
    "\n",
    "In probability theory and statistics, the **chi-square distribution (also chi-squared or χ2-distribution) with _k_ degrees of freedom is the distribution of a sum of the squares of _k_ independent standard normal random variables**. \n",
    "\n",
    "The chi-square distribution is a special case of the [gamma distribution](https://en.wikipedia.org/wiki/Gamma_distribution) and is one of the most widely used probability distributions in inferential statistics, notably in hypothesis testing or in construction of confidence intervals.\n",
    "\n",
    "The probability density function (pdf) of the chi-square distribution is\n",
    "\n",
    "$$ f(x;\\,k)={\\begin{cases}{\\dfrac {x^{{\\frac {k}{2}}-1}e^{-{\\frac {x}{2}}}}{2^{\\frac {k}{2}}\\Gamma \\left({\\frac {k}{2}}\\right)}},&x>0;\\\\0,&{\\text{otherwise}}.\\end{cases}} $$\n",
    "\n",
    "where $\\Gamma({k/2})$ denotes the gamma function, which has closed-form values for integer $k$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.chisquare(df=3,size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_normal(k,num_experiments=100):\n",
    "    dist = []\n",
    "    for i in range(num_experiments):\n",
    "        total = 0\n",
    "        for i in range(k):\n",
    "            total+=(float(np.random.normal()))**2\n",
    "        dist.append(total)\n",
    "    return np.array(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.random.chisquare(df=5,size=1000)\n",
    "plt.hist(a1,bins=25,edgecolor='k',color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = sum_normal(k=5,num_experiments=1000)\n",
    "plt.hist(a2,bins=25,edgecolor='k',color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-distribution as a ratio of two scaled Chi-squared distributions\n",
    "In probability theory and statistics, the F-distribution, also known as **Snedecor's F distribution** or the **Fisher–Snedecor distribution** (after [Ronald Fisher](https://en.wikipedia.org/wiki/Ronald_Fisher) and [George W. Snedecor](https://en.wikipedia.org/wiki/George_W._Snedecor)) is a continuous probability distribution that arises frequently as the null distribution of a test statistic, most notably in the analysis of variance (ANOVA), e.g., F-test.\n",
    "\n",
    "Then the probability density function (pdf) for X is given by\n",
    "\n",
    "$$ {\\begin{aligned}f(x;d_{1},d_{2})&={\\frac {\\sqrt {\\frac {(d_{1}\\,x)^{d_{1}}\\,\\,d_{2}^{d_{2}}}{(d_{1}\\,x+d_{2})^{d_{1}+d_{2}}}}}{x\\,\\mathrm {B} \\!\\left({\\frac {d_{1}}{2}},{\\frac {d_{2}}{2}}\\right)}}\\\\&={\\frac {1}{\\mathrm {B} \\!\\left({\\frac {d_{1}}{2}},{\\frac {d_{2}}{2}}\\right)}}\\left({\\frac {d_{1}}{d_{2}}}\\right)^{\\frac {d_{1}}{2}}x^{{\\frac {d_{1}}{2}}-1}\\left(1+{\\frac {d_{1}}{d_{2}}}\\,x\\right)^{-{\\frac {d_{1}+d_{2}}{2}}}\\end{aligned}} $$\n",
    "\n",
    "Here $\\mathrm {B}$ is the beta function. In many applications, the parameters $d_1$ and $d_2$ are positive integers, but the distribution is well-defined for positive real values of these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.f(dfnum=5,dfden=25,size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.random.f(dfnum=5,dfden=25,size=1000)\n",
    "plt.hist(a1,bins=25,edgecolor='k',color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = sum_normal(k=5,num_experiments=1000)\n",
    "a3 = sum_normal(k=25,num_experiments=1000)\n",
    "a4 = a2/a3\n",
    "\n",
    "plt.hist(a4,bins=25,edgecolor='k',color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student's t-distribution\n",
    "\n",
    "In probability and statistics, Student's t-distribution (or simply the t-distribution) is any member of a family of continuous probability distributions that arises when **estimating the mean of a normally distributed population in situations where the sample size is small and population standard deviation is unknown**. It was developed by [William Sealy Gosset](https://en.wikipedia.org/wiki/William_Sealy_Gosset) under the pseudonym Student.\n",
    "\n",
    "The t-distribution plays a role in a number of widely used statistical analyses, including Student's t-test for assessing the statistical significance of the difference between two sample means, the construction of confidence intervals for the difference between two population means, and in linear regression analysis. The Student's t-distribution also arises in the Bayesian analysis of data from a normal family.\n",
    "\n",
    "Student's t-distribution has the probability density function given by,\n",
    "$$ f(t)={\\frac {\\Gamma ({\\frac {\\nu +1}{2}})}{{\\sqrt {\\nu \\pi }}\\,\\Gamma ({\\frac {\\nu }{2}})}}\\left(1+{\\frac {t^{2}}{\\nu }}\\right)^{\\!-{\\frac {\\nu +1}{2}},\\!} $$\n",
    "\n",
    "where $\\nu$ is the number of degrees of freedom and $\\Gamma$ is the gamma function. \n",
    "\n",
    "![t_dist_538](https://raw.githubusercontent.com/tirthajyoti/Stats-Maths-with-Python/master/images/t_dist_538.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=np.random.standard_t(10,size=10000)\n",
    "plt.hist(a1,bins=50,edgecolor='k',color='orange',density=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
