{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Distribution: Introduction\n",
    "\n",
    "In [probability theory](https://en.wikipedia.org/wiki/Probability_theory) and [statistics](https://en.wikipedia.org/wiki/statistics), a probability distribution is a [mathematical function](https://en.wikipedia.org/wiki/Function_(mathematics)) that, stated in simple terms, can be thought of as providing the probabilities of occurrence of different possible outcomes in an experiment. \n",
    "\n",
    "In more technical terms, the probability distribution is a description of a random phenomenon in terms of the probabilities of events. Examples of random phenomena can include the results of an experiment or survey. A probability distribution is defined in terms of an underlying sample space, which is the set of all possible outcomes of the random phenomenon being observed. The sample space may be the set of [real numbers](https://en.wikipedia.org/wiki/Real_number) or a higher-dimensional [vector space](https://en.wikipedia.org/wiki/Vector_space), or it may be a list of non-numerical values; for example, the sample space of a coin flip would be {_heads, tails_}.\n",
    "\n",
    "![Bell curve](https://upload.wikimedia.org/wikipedia/commons/8/8c/Standard_deviation_diagram.svg)\n",
    "\n",
    "### Discrete and Continuous Distributions\n",
    "\n",
    "Probability distributions are generally divided into two classes. A __discrete probability distribution__ (applicable to the scenarios where the set of possible outcomes is discrete, such as a coin toss or a roll of dice) can be encoded by a discrete list of the probabilities of the outcomes, known as a [probability mass function](https://en.wikipedia.org/wiki/Probability_mass_function). On the other hand, a __continuous probability distribution__ (applicable to the scenarios where the set of possible outcomes can take on values in a continuous range (e.g. real numbers), such as the temperature on a given day) is typically described by probability density functions (with the probability of any individual outcome actually being 0). Such distributions are generally described with the help of [probability density functions](https://en.wikipedia.org/wiki/Probability_density_function).\n",
    "\n",
    "### Univariate and Multivariate Distributions\n",
    "\n",
    "A probability distribution whose sample space is the set of real numbers is called __univariate__, while a distribution whose sample space is a vector space is called __multivariate__. A univariate distribution gives the probabilities of a single random variable taking on various alternative values; a multivariate distribution (a [joint probability distribution](https://en.wikipedia.org/wiki/Joint_probability_distribution)) gives the probabilities of a random vector—a list of two or more random variables—taking on various combinations of values. Important and commonly encountered univariate probability distributions include the [binomial distribution](https://en.wikipedia.org/wiki/Binomial_distribution), the [hypergeometric distribution](https://en.wikipedia.org/wiki/Hypergeometric_distribution), and the [normal distribution](https://en.wikipedia.org/wiki/Normal_distribution). The [multivariate normal distribution](https://en.wikipedia.org/wiki/Multivariate_normal_distribution) is a commonly encountered multivariate distribution.\n",
    "![Hypergeometric distribution](https://upload.wikimedia.org/wikipedia/commons/c/c1/HypergeometricPDF.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=====================================================================================================================**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Essential Terminologies\n",
    "\n",
    "* __Mode__: for a discrete random variable, the value with highest probability (the location at which the probability mass function has its peak); for a continuous random variable, a location at which the probability density function has a local peak.\n",
    "* __Support__: the smallest closed set whose complement has probability zero.\n",
    "* __Head__: the range of values where the pmf or pdf is relatively high.\n",
    "* __Tail__: the complement of the head within the support; the large set of values where the pmf or pdf is relatively low.\n",
    "* __Expected value or mean__: the weighted average of the possible values, using their probabilities as their weights; or the continuous analog thereof.\n",
    "* __Median__: the value such that the set of values less than the median, and the set greater than the median, each have probabilities no greater than one-half.\n",
    "* __Variance__: the second moment of the pmf or pdf about the mean; an important measure of the dispersion of the distribution.\n",
    "* __Standard deviation__: the square root of the variance, and hence another measure of dispersion.\n",
    "\n",
    "\n",
    "\n",
    "* __Symmetry__: a property of some distributions in which the portion of the distribution to the left of a specific value is a mirror image of the portion to its right.\n",
    "* __Skewness__: a measure of the extent to which a pmf or pdf \"leans\" to one side of its mean. The third standardized moment of the distribution.\n",
    "* __Kurtosis__: a measure of the \"fatness\" of the tails of a pmf or pdf. The fourth standardized moment of the distribution.\n",
    "\n",
    "![kurtosis](https://anotherbloodybullshitblog.files.wordpress.com/2016/01/normal-not-always-the-norm.gif?w=809)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=====================================================================================================================**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python library for statistical distributions\n",
    "\n",
    "The __[scipy.stats](https://docs.scipy.org/doc/scipy/reference/stats.html)__ library is the quintessential collection of statistical functions and methods for various probability distribuutions in the Python ecosystem. We leverage this package fully for this notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=====================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook, we discuss about most important _discrete distributions_\n",
    "* **Bernoulli distribution**\n",
    "* **Binomial distribution**\n",
    "* **Poisson distribution**\n",
    "* **Geometric distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=====================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulii distribution\n",
    "\n",
    "The Bernoulli distribution, named after Swiss mathematician [Jacob Bernoulli](https://en.wikipedia.org/wiki/Jacob_Bernoulli), is the probability distribution of a random variable which takes the value 1 with probability $p$ and the value 0 with probability $q = 1 − p$ — i.e., the probability distribution of any single experiment that asks a ___yes–no question___; the question results in a boolean-valued outcome, a single bit of information whose value is success/yes/true/one with probability $p$ and failure/no/false/zero with probability $q$. \n",
    "\n",
    "It can be used to represent a coin toss where 1 and 0 would represent \"head\" and \"tail\" (or vice versa), respectively. In particular, unfair coins would have $p ≠ 0.5$.\n",
    "\n",
    "The probability mass function $f$ of this distribution, over possible outcomes $k$, is\n",
    "\n",
    "$${\\displaystyle f(k;p)={\\begin{cases}p&{\\text{if }}k=1,\\\\[6pt]1-p&{\\text{if }}k=0.\\end{cases}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import bernoulli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate random variates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p=0.5 i.e. fair coin ( pièce parfaite non truquée)\n",
    "bernoulli.rvs(p=0.5,size=10)# 10 rélaisation ( jeter la pièce 10 fois )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p=0.2 i.e. more tails than heads\n",
    "bernoulli.rvs(p=0.2,size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p=0.8 i.e. more heads than tails\n",
    "bernoulli.rvs(p=0.8,size=10)\n",
    "\n",
    "# 1 ===> pile \n",
    "# 0 ===> face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note, a single run or even a small number of runs may not produce the expected distribution of 1's and 0's. For example, if you assign $p=0.5$, you may not get half 1's and half 0's every time you evaluate the function. Experiment with $N$ number of trials to see how the probability distribution gradually centers around 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N_trials = [10,25,100,250,1000,10000,25000] # Number of trials\n",
    "pr=0.2 # Fair coin toss probability\n",
    "av = [] # Empty list to store the average of the random variates\n",
    "\n",
    "# Generate 10 variates every time and take the average. That should be # of 1's i.e. 0.5 for a fair coin.\n",
    "for i in N_trials:\n",
    "    for n in range(1,i+1):\n",
    "        av.append(np.mean(bernoulli.rvs(p=pr,size=10)))\n",
    "    if (i==10):\n",
    "        plt.title(\"Distribution with {} trials of 10 coin tosses\".format(i))\n",
    "        plt.hist(av,bins=10)\n",
    "        plt.xlim(0.0,1.0)\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.title(\"Distribution with {} trials of 10 coin tosses\".format(i))\n",
    "        plt.hist(av,bins=25)\n",
    "        plt.xlim(0.0,1.0)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean, variance, skew, and kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"A fair coin is spinning...\\n\"+\"-\"*30)\n",
    "pr=0.5 # Fair coin toss probability\n",
    "mean, var, skew, kurt = bernoulli.stats(p=pr, moments='mvsk')\n",
    "print(\"Mean:\",mean)\n",
    "print(\"Variance:\",var)\n",
    "print(\"Skew:\",skew)\n",
    "print(\"Kurtosis:\",kurt)\n",
    "print(\"\\nNow a biased coin is spinning...\\n\"+\"-\"*35)\n",
    "pr=0.2 # Biased coin toss probability\n",
    "mean, var, skew, kurt = bernoulli.stats(p=pr, moments='mvsk')\n",
    "print(\"Mean:\",mean)\n",
    "print(\"Variance:\",var)\n",
    "print(\"Skew:\",skew)\n",
    "print(\"Kurtosis:\",kurt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard deviation, mean, median, entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nA biased coin with likelihood 0.3 is spinning...\\n\"+\"-\"*50)\n",
    "pr=0.3\n",
    "print(\"Std. dev:\",bernoulli.std(p=pr))\n",
    "print(\"Mean:\",bernoulli.mean(p=pr))\n",
    "print(\"Median:\",bernoulli.median(p=pr))\n",
    "print(\"Entropy:\",bernoulli.entropy(p=pr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability mass function (pmf) and cumulative distribution function (cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv = bernoulli(0.6)\n",
    "x=0\n",
    "print(\"Probability mass function for {}: {}\".format(x,rv.pmf(x)))\n",
    "x=0.5\n",
    "print(\"Probability mass function for {}: {}\".format(x,rv.pmf(x)))\n",
    "x=1.0\n",
    "print(\"Probability mass function for {}: {}\".format(x,rv.pmf(x)))\n",
    "x=1.2\n",
    "print(\"Probability mass function for {}: {}\".format(x,rv.pmf(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CDF for x < 0:\",rv.cdf(-2))\n",
    "print(\"CDF for 0< x <1:\",rv.cdf(0.75))\n",
    "print(\"CDF for x >1:\",rv.cdf(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the complete list of functions and methods please [see this link](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bernoulli.html#scipy.stats.bernoulli)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=====================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binomial distribution\n",
    "\n",
    "The binomial distribution with parameters $n$ and $p$ is the discrete probability distribution of the number of successes in a sequence of $n$ independent experiments, each asking a _yes–no question_, and each with its own boolean-valued outcome: a random variable containing single bit of information: success/yes/true/one (with probability $p$) or failure/no/false/zero (with probability $q = 1 − p$). A single success/failure experiment is also called a __Bernoulli trial__ or __Bernoulli experiment__ and a sequence of outcomes is called a __Bernoulli process__. For a single trial, i.e., n = 1, the binomial distribution is a Bernoulli distribution. The binomial distribution is the basis for the popular [binomial test](https://en.wikipedia.org/wiki/Binomial_test) of [statistical significance](https://en.wikipedia.org/wiki/Statistical_significance).\n",
    "\n",
    "The binomial distribution is frequently used to model the number of successes in a sample of size n drawn with replacement from a population of size N. If the sampling is carried out without replacement, the draws are not independent and so the resulting distribution is a __[hypergeometric distribution](https://en.wikipedia.org/wiki/Hypergeometric_distribution)__, not a binomial one. However, for N much larger than n, the binomial distribution remains a good approximation, and is widely used.\n",
    "\n",
    "In general, if the random variable $X$ follows the binomial distribution with parameters n ∈ ℕ and p ∈ [0,1], we write X ~ B(n, p). The probability of getting exactly $k$ successes in $n$ trials is given by the probability mass function:\n",
    "\n",
    "$${\\Pr(k;n,p)=\\Pr(X=k)={n \\choose k}p^{k}(1-p)^{n-k}}$$\n",
    "\n",
    "for k = 0, 1, 2, ..., n, where\n",
    "\n",
    "$${\\displaystyle {\\binom {n}{k}}={\\frac {n!}{k!(n-k)!}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import binom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate random variates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 coins are flipped (or 1 coin is flipped 8 times), each with probability of success (1) of 0.25\n",
    "# This trial/experiment is repeated for 10 times\n",
    "k=binom.rvs(8,0.25,size=10000)\n",
    "print(\"Number of success for each trial:\",k)\n",
    "print(\"Average of the success:\", np.mean(k))\n",
    "\n",
    "\"\"\"\n",
    "n=8====>represente le nombre n ( le nombre d'expérience)\n",
    "p=0.25 ===> représente la probabilité d'avoir un succé lorsque on tente une fois l'expériance\n",
    "\n",
    "E(X)=n*p=8*0.25=2\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moments - Mean, variance, skew, and kurtosis\n",
    "\n",
    "$$E(X) = n.p,\\ Var(X)= n.p(1 - p), \\textbf{skewness}= \\frac{1-2p}{\\sqrt{n.p(1-p)}}, \\ \\textbf{kurtosis}= \\frac{1-6p(1-p)}{n.p(1-p)}$$\n",
    "\n",
    "Just as an example, the proof for mean is given below,\n",
    "\n",
    "${\\displaystyle \\mu =\\sum _{i=0}^{n}x_{i}p_{i},}$\n",
    "${\\displaystyle {\\begin{aligned}\\mu &=\\sum _{k=0}^{n}k{\\binom {n}{k}}p^{k}(1-p)^{n-k}\\\\&=np\\sum _{k=0}^{n}k{\\frac {(n-1)!}{(n-k)!k!}}p^{k-1}(1-p)^{(n-1)-(k-1)}\\\\&=np\\sum _{k=1}^{n}{\\frac {(n-1)!}{((n-1)-(k-1))!(k-1)!}}p^{k-1}(1-p)^{(n-1)-(k-1)}\\\\&=np\\sum _{k=1}^{n}{\\binom {n-1}{k-1}}p^{k-1}(1-p)^{(n-1)-(k-1)}\\\\&=np\\sum _{\\ell =0}^{n-1}{\\binom {n-1}{\\ell }}p^{\\ell }(1-p)^{(n-1)-\\ell }&&{\\text{with }}\\ell :=k-1\\\\&=np\\sum _{\\ell =0}^{m}{\\binom {m}{\\ell }}p^{\\ell }(1-p)^{m-\\ell }&&{\\text{with }}m:=n-1\\\\&=np(p+(1-p))^{m}\\\\&=np\\end{aligned}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"A fair coin is spinning 5 times\\n\"+\"-\"*35)\n",
    "pr=0.5 # Fair coin toss probability\n",
    "n=5\n",
    "mean, var, skew, kurt = binom.stats(n=n,p=pr, moments='mvsk')\n",
    "print(\"Mean:\",mean)\n",
    "print(\"Variance:\",var)\n",
    "print(\"Skew:\",skew)\n",
    "print(\"Kurtosis:\",kurt)\n",
    "print(\"\\nNow a biased coin is spinning 5 times...\\n\"+\"-\"*45)\n",
    "pr=0.7 # Biased coin toss probability\n",
    "n=5\n",
    "mean, var, skew, kurt = binom.stats(n=n,p=pr, moments='mvsk')\n",
    "print(\"Mean:\",mean)\n",
    "print(\"Variance:\",var)\n",
    "print(\"Skew:\",skew)\n",
    "print(\"Kurtosis:\",kurt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard deviation, mean, median, entropy\n",
    "\n",
    "_Entropy_ = $\\frac12 \\log_2 \\big( 2\\pi e\\, np(1-p) \\big) + O \\left( \\frac{1}{n} \\right)$\n",
    "\n",
    "_std.dev_ = $\\sqrt{n.p(1-p)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=5\n",
    "pr=0.7\n",
    "print(\"\\n{} biased coins with likelihood {} are spinning...\\n\".format(n,pr)+\"-\"*50)\n",
    "print(\"Std. dev:\",binom.std(n=n,p=pr))\n",
    "print(\"Mean:\",binom.mean(n=n,p=pr))\n",
    "print(\"Median:\",binom.median(n=n,p=pr))\n",
    "print(\"Entropy:\",binom.entropy(n=n,p=pr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the probability mass function (pmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=40\n",
    "pr=0.5\n",
    "rv = binom(n,pr)\n",
    "x=np.arange(0,41,1)\n",
    "pmf1 = rv.pmf(x)\n",
    "\n",
    "n=40\n",
    "pr=0.15\n",
    "rv = binom(n,pr)\n",
    "x=np.arange(0,41,1)\n",
    "pmf2 = rv.pmf(x)\n",
    "\n",
    "n=50\n",
    "pr=0.6\n",
    "rv = binom(n,pr)\n",
    "x=np.arange(0,41,1)\n",
    "pmf3 = rv.pmf(x)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title(\"Probability mass function: $\\\\binom{n}{k}\\, p^k (1-p)^{n-k}$\\n\",fontsize=20)\n",
    "plt.scatter(x,pmf1)\n",
    "plt.scatter(x,pmf2)\n",
    "plt.scatter(x,pmf3,c='k')\n",
    "plt.legend([\"$n=40, p=0.5$\",\"$n=40, p=0.3$\",\"$n=50, p=0.6$\"],fontsize=15)\n",
    "plt.xlabel(\"Number of successful trials ($k$)\",fontsize=15)\n",
    "plt.ylabel(\"Probability of success\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the cumulative distrubition function (cdf)\n",
    "\n",
    "Cumulative distribution function for binomial distribution can also be represented in terms of the [regularized incomplete beta function](https://en.wikipedia.org/wiki/Regularized_incomplete_beta_function), as follows\n",
    "\n",
    "$${\\displaystyle {\\begin{aligned}F(k;n,p)&=\\Pr(X\\leq k)\\\\&=I_{1-p}(n-k,k+1)\\\\&=(n-k){n \\choose k}\\int _{0}^{1-p}t^{n-k-1}(1-t)^{k}\\,dt.\\end{aligned}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=40\n",
    "pr=0.5\n",
    "rv = binom(n,pr)\n",
    "x=np.arange(0,41,1)\n",
    "cdf1 = rv.cdf(x)\n",
    "\n",
    "n=40\n",
    "pr=0.3\n",
    "rv = binom(n,pr)\n",
    "x=np.arange(0,41,1)\n",
    "cdf2 = rv.cdf(x)\n",
    "\n",
    "n=50\n",
    "pr=0.6\n",
    "rv = binom(n,pr)\n",
    "x=np.arange(0,41,1)\n",
    "cdf3 = rv.cdf(x)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title(\"Cumulative distribution function: $I_{1-p}(n - k, 1 + k)$\\n\",fontsize=20)\n",
    "plt.scatter(x,cdf1)\n",
    "plt.scatter(x,cdf2)\n",
    "plt.scatter(x,cdf3,c='k')\n",
    "plt.legend([\"$n=40, p=0.5$\",\"$n=40, p=0.3$\",\"$n=50, p=0.6$\"],fontsize=15)\n",
    "plt.xlabel(\"Number of successful trials\",fontsize=15)\n",
    "plt.ylabel(\"Cumulative probability of success\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interval that contains a specific percentage of distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=40\n",
    "pr=0.3\n",
    "percent=25\n",
    "interval = binom.interval(percent/100,n,pr,loc=0)\n",
    "print(\"Interval that contains {} percent of distribution is: {}\".format(percent,interval))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(X\\in [11,13])=0.25$$\n",
    "\n",
    "$$X \\sim B(n=40,p=0.3)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the complete list of functions and methods please [see this link](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html#scipy.stats.binom)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=====================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson Distribution\n",
    "\n",
    "The Poisson distribution (named after French mathematician Siméon Denis Poisson), is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time or space if these events occur with a known constant rate and independently of the time since the last event. The Poisson distribution can also be used for the number of events in other specified intervals such as distance, area or volume.\n",
    "\n",
    "For instance, an individual keeping track of the amount of mail they receive each day may notice that they receive an average number of 4 letters per day. If receiving any particular piece of mail does not affect the arrival times of future pieces of mail, i.e., if pieces of mail from a wide range of sources arrive independently of one another, then a reasonable assumption is that the number of pieces of mail received in a day obeys a Poisson distribution. Other examples that may follow a Poisson include\n",
    "* number of phone calls received by a call center per hour \n",
    "* number of decay events per second from a radioactive source\n",
    "* The number of meteors greater than 1 meter diameter that strike Earth in a year\n",
    "* The number of patients arriving in an emergency room between 10 and 11 pm\n",
    "\n",
    "** Poisson distribution is a limiting case of a Binomial Distribution where the number of trials is sufficiently bigger than the number of successes one is asking about i.e. $n>>1>>p$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import poisson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display probability mass function (pmf)\n",
    "\n",
    "An event can occur 0, 1, 2, … times in an interval. The average number of events in an interval is designated $\\lambda$. This is the event rate, also called the rate parameter. The probability of observing k events in an interval is given by the equation\n",
    "\n",
    "${\\displaystyle P(k{\\text{ events in interval}})=e^{-\\lambda }{\\frac {\\lambda ^{k}}{k!}}}$\n",
    "\n",
    "where,\n",
    "\n",
    "${\\lambda}$ is the average number of events per interval\n",
    "\n",
    "e is the number 2.71828... (Euler's number) the base of the natural logarithms\n",
    "\n",
    "k takes values 0, 1, 2, …\n",
    "k! = k × (k − 1) × (k − 2) × … × 2 × 1 is the factorial of k."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ X \\sim \\text{poisson}(0.2)$$\n",
    "$X$ représente le nombre de client qui arrivent au mall of sousse dans un intervalle de temps\n",
    "\n",
    "${\\displaystyle P({\\text{ 50 personnes arrivent au mall of sousse dans un intervalle de temp}})=e^{-0.2 }{\\frac {0.2 ^{50}}{50!}}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la=0.5\n",
    "rv = poisson(la)\n",
    "x=np.arange(0,11,1)\n",
    "pmf1 = rv.pmf(x)\n",
    "\n",
    "la=1\n",
    "rv = poisson(la)\n",
    "x=np.arange(0,11,1)\n",
    "pmf2 = rv.pmf(x)\n",
    "\n",
    "la=5\n",
    "rv = poisson(la)\n",
    "x=np.arange(0,11,1)\n",
    "pmf3 = rv.pmf(x)\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.title(\"Probability mass function: $e^{-\\lambda}{(\\lambda^k/k!)}$\\n\",fontsize=20)\n",
    "plt.scatter(x,pmf1,s=100)\n",
    "plt.scatter(x,pmf2,s=100)\n",
    "plt.scatter(x,pmf3,c='k',s=100)\n",
    "plt.legend([\"$\\lambda=0.5$\",\"$\\lambda=1$\",\"$\\lambda=5$\"],fontsize=15)\n",
    "plt.xlabel(\"Number of occurences ($k$)\",fontsize=15)\n",
    "plt.ylabel(\"$Pr(X=k)$\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display cumulative distribution function (cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la=0.5\n",
    "rv = poisson(la)\n",
    "x=np.arange(0,11,1)\n",
    "cdf1 = rv.cdf(x)\n",
    "\n",
    "la=2\n",
    "rv = poisson(la)\n",
    "x=np.arange(0,11,1)\n",
    "cdf2 = rv.cdf(x)\n",
    "\n",
    "la=5\n",
    "rv = poisson(la)\n",
    "x=np.arange(0,11,1)\n",
    "cdf3 = rv.cdf(x)\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.title(\"Cumulative distribution function\\n\",fontsize=20)\n",
    "plt.scatter(x,cdf1,s=100)\n",
    "plt.scatter(x,cdf2,s=100)\n",
    "plt.scatter(x,cdf3,c='k',s=100)\n",
    "plt.legend([\"$\\lambda=0.5$\",\"$\\lambda=2$\",\"$\\lambda=5$\"],fontsize=15)\n",
    "plt.xlabel(\"Number of occurences ($k$)\",fontsize=15)\n",
    "plt.ylabel(\"Cumulative distribution function\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moments - mean, variance, skew, and kurtosis\n",
    "Various moments of a Poisson distributed random variable $X$ are as follows:\n",
    "\n",
    "$$ E(X)=\\lambda,\\ Var(X)=\\lambda,\\ \\textbf{skewness}=\\frac {1}{\\sqrt{\\lambda}},\\ \\textbf{kurtosis}=\\frac{1}{\\lambda}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For small lambda\\n\"+\"-\"*25)\n",
    "la=0.5\n",
    "mean, var, skew, kurt = poisson.stats(mu=la, moments='mvsk')\n",
    "print(\"Mean:\",mean)\n",
    "print(\"Variance:\",var)\n",
    "print(\"Skew:\",skew)\n",
    "print(\"Kurtosis:\",kurt)\n",
    "print(\"\\nNow for large lambda\\n\"+\"-\"*30)\n",
    "la=5\n",
    "mean, var, skew, kurt = poisson.stats(mu=la, moments='mvsk')\n",
    "print(\"Mean:\",mean)\n",
    "print(\"Variance:\",var)\n",
    "print(\"Skew:\",skew)\n",
    "print(\"Kurtosis:\",kurt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard deviation, mean, median, entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la=5\n",
    "print(\"For lambda = {}\\n-------------------------\".format(la))\n",
    "print(\"Std. dev:\",poisson.std(mu=la))\n",
    "print(\"Mean:\",poisson.mean(mu=la))\n",
    "print(\"Median:\",poisson.median(mu=la))\n",
    "print(\"Entropy:\",poisson.entropy(mu=la))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate random variates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la=5\n",
    "r = poisson.rvs(mu=la, size=20)\n",
    "print(\"Random variates with lambda={}: {}\".format(la,r))\n",
    "\n",
    "la=0.5\n",
    "r = poisson.rvs(mu=la, size=20)\n",
    "print(\"Random variates with lambda={}: {}\".format(la,r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show that Poisson distribution is a limiting case of Binomial distribution for large $n$ and small $p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact,interactive\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rv_plot(n,p):\n",
    "    n=n\n",
    "    la=n*p\n",
    "    rv_binom=binom(n,p)\n",
    "    rv_poisson=poisson(la)\n",
    "    x=np.arange(1,n+1,1)\n",
    "    pmf_binom=rv_binom.pmf(x)\n",
    "    pmf_poisson=rv_poisson.pmf(x)\n",
    "    y_max=max(max(pmf_binom),max(pmf_poisson))*1.25\n",
    "    plt.figure(figsize=(max(7,int(n/3)),5))\n",
    "    plt.scatter(x,pmf_binom,s=100,edgecolors='k')\n",
    "    plt.scatter(x,pmf_poisson,s=100,edgecolors='k')\n",
    "    plt.legend(['Binomial distribution, $n$:{},$p$:{}'.format(n,p),\n",
    "                'Poisson distribution, $\\lambda$:{}'.format(n*p)],fontsize=12)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.xlabel(\"Occurences ($k$)\",fontsize=15)\n",
    "    plt.ylabel(\"$Pr(X=k$\",fontsize=15)\n",
    "    plt.ylim(ymin=-0.05,ymax=y_max)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Move the sliders on sample size (n) or probability (p) and see how the two distributions approach each other. \\\n",
    "\\nNote,that lambda or rate parameter of the Poisson distribution is always the product of n and p of the \\nBinomial distribution\")\n",
    "\n",
    "w=interactive(rv_plot,n = widgets.IntSlider(value=10,min=10,max=40,step=5,description='Sample: $n$'),\n",
    "            p=widgets.FloatSlider(value=0.1,min=0.1,max=0.8,step=0.05,description='Probability: $p$'))\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the complete list of functions and methods please [see this link](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.poisson.html#scipy.stats.poisson)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=====================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometric distribution\n",
    "\n",
    "The geometric distribution is either of two discrete probability distributions:\n",
    "\n",
    "    The probability distribution of the number X of Bernoulli trials needed to get one success, supported on the set { 1, 2, 3, ...}\n",
    "    The probability distribution of the number Y = X − 1 of failures before the first success, supported on the set { 0, 1, 2, 3, ... }\n",
    "\n",
    "Which of these one calls \"the\" geometric distribution is a matter of convention and convenience.\n",
    "\n",
    "These two different geometric distributions should not be confused with each other. Often, the name shifted geometric distribution is adopted for the former one (distribution of the number $X$); however, to avoid ambiguity, it is considered wise to indicate which is intended, by mentioning the support explicitly.\n",
    "\n",
    "The geometric distribution gives the probability that the first occurrence of success requires $k$ independent trials, each with success probability $p$. If the probability of success on each trial is $p$, then the probability that the $k^{th}$ trial (out of $k$ trials) is the first success is\n",
    "\n",
    "${\\displaystyle \\Pr(X=k)=(1-p)^{k-1}\\,p\\,}$\n",
    "\n",
    "for $k = 1, 2, 3, ....$\n",
    "\n",
    "The above form of the geometric distribution is used for modeling the number of trials up to and including the first success. By contrast, the following form of the geometric distribution is used for modeling the number of failures until the first success:\n",
    "\n",
    "${\\displaystyle \\Pr(Y=k)=(1-p)^{k}\\,p\\,}$\n",
    "\n",
    "for $k = 0, 1, 2, 3, ....$\n",
    "\n",
    "In either case, the sequence of probabilities is a geometric sequence.\n",
    "\n",
    "The geometric distribution is an appropriate model if the following assumptions are true.\n",
    "\n",
    "    The phenomenon being modelled is a sequence of independent trials.\n",
    "    There are only two possible outcomes for each trial, often designated success or failure.\n",
    "    The probability of success, p, is the same for every trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import geom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate some random variates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=geom.rvs(p=0.1,size=10)\n",
    "print(r)\n",
    "\n",
    "r=geom.rvs(p=0.5,size=10)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display probability mass function (pmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0.1\n",
    "rv = geom(p)\n",
    "x=np.arange(1,11,1)\n",
    "pmf1 = rv.pmf(x)\n",
    "\n",
    "p=0.25\n",
    "rv = geom(p)\n",
    "x=np.arange(1,11,1)\n",
    "pmf2 = rv.pmf(x)\n",
    "\n",
    "p=0.75\n",
    "rv = geom(p)\n",
    "x=np.arange(1,11,1)\n",
    "pmf3 = rv.pmf(x)\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.title(\"Probability mass function: $(1-p)^{k-1}p$\\n\",fontsize=20)\n",
    "plt.scatter(x,pmf1,s=100)\n",
    "plt.scatter(x,pmf2,s=100)\n",
    "plt.scatter(x,pmf3,c='k',s=100)\n",
    "plt.plot(x,pmf1)\n",
    "plt.plot(x,pmf2)\n",
    "plt.plot(x,pmf3,c='k')\n",
    "plt.legend([\"$p=0.1$\",\"$p=0.25$\",\"$p=0.75$\"],fontsize=15)\n",
    "plt.xlabel(\"Number of trials till first success ($k$)\",fontsize=15)\n",
    "plt.ylabel(\"$Pr(X=x)$\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display cumulative distribution function (cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0.1\n",
    "rv = geom(p)\n",
    "x=np.arange(1,11,1)\n",
    "cdf1 = rv.cdf(x)\n",
    "\n",
    "p=0.25\n",
    "rv = geom(p)\n",
    "x=np.arange(1,11,1)\n",
    "cdf2 = rv.cdf(x)\n",
    "\n",
    "p=0.75\n",
    "rv = geom(p)\n",
    "x=np.arange(1,11,1)\n",
    "cdf3 = rv.cdf(x)\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.title(\"Cumulative distribution function: $1-(1-p)^k$\\n\",fontsize=20)\n",
    "plt.scatter(x,cdf1,s=100)\n",
    "plt.scatter(x,cdf2,s=100)\n",
    "plt.scatter(x,cdf3,c='k',s=100)\n",
    "plt.plot(x,cdf1)\n",
    "plt.plot(x,cdf2)\n",
    "plt.plot(x,cdf3,c='k')\n",
    "plt.legend([\"$p=0.1$\",\"$p=0.25$\",\"$p=0.75$\"],fontsize=15)\n",
    "plt.xlabel(\"Number of trials till first success ($k$)\",fontsize=15)\n",
    "plt.ylabel(\"$Pr(X\\leq x)$\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected value, variance, skewness, kurtosis\n",
    "Various moments of a geometrically distributed random variable $X$ are as follows:\n",
    "\n",
    "$$ E(X)=\\frac {1}{p},\\ Var(X)=\\frac {1-p}{p^2},\\ \\textbf{skewness}=\\frac {2-p}{\\sqrt{1-p}},\\ \\textbf{kurtosis}=6+\\frac{p^2}{1-p}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For small p=0.1\\n\"+\"-\"*25)\n",
    "p=0.1\n",
    "mean, var, skew, kurt = geom.stats(p=p, moments='mvsk')\n",
    "print(\"Mean:\",mean)\n",
    "print(\"Variance:\",var)\n",
    "print(\"Skew:\",skew)\n",
    "print(\"Kurtosis:\",kurt)\n",
    "print(\"\\nNow for large p=0.8\\n\"+\"-\"*30)\n",
    "p=0.8\n",
    "mean, var, skew, kurt = geom.stats(p=p, moments='mvsk')\n",
    "print(\"Mean:\",mean)\n",
    "print(\"Variance:\",var)\n",
    "print(\"Skew:\",skew)\n",
    "print(\"Kurtosis:\",kurt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the complete list of functions and methods please [see this link](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.geom.html#scipy.stats.geom)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=====================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to calculate expected value of a function (of one variable) with respect to a probability distribution?\n",
    "Let's say a rational function is $f(x)=\\frac {2x^2+3x+1}{x^3+4}$\n",
    "Therefore, the expected value of that function w.r.t. to a distribution and with lower bound $\\textbf{a}$ and upper bound $\\textbf{b}$ is given by,\n",
    "\n",
    "$$\\int_{a}^{b}{\\frac {2x^2+3x+1}{x^3+4}}.{\\ p(x)}$$\n",
    "where $p(x)$ is the probability mass function corresponding to the distribution.\n",
    "\n",
    "The awesome scipy.stats allows calculation of such expected value through the ___.expect( ) method___."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic(x):\n",
    "    return ((2*x**2+3*x+1)/(x**3+4))\n",
    "p=0.2 # Shape parameter for the distribution, here p for Geometric distribution\n",
    "lb=-2 # Lower bound of the integral\n",
    "ub=2 # Upper bound of the integral\n",
    "e = geom.expect(quadratic,args=(p,),lb=0,ub=ub)\n",
    "print(\"Expected value:\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "dd2f083c7091592f6e910b42e81e3d9326587f6134c1427a9ed8e8691fd16a23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
